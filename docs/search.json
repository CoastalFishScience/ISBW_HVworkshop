[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this site\n\n1 + 1\n\n[1] 2"
  },
  {
    "objectID": "comp.html",
    "href": "comp.html",
    "title": "ISWB 15 Hypervolume Workshop",
    "section": "",
    "text": "R and RStudio\nR and RStudio are separate downloads and installations. R is the underlying statistical computing environment, but using R alone is no fun. RStudio is a graphical integrated development environment (IDE) that makes using R much easier and more interactive. You need to install R before you install RStudio. In the sections below are the instructions for installing R and R Studio on your operating system.\n\nWindows\n\nIf you already have R and RStudio installed\n\nOpen RStudio, and click on “Help” &gt; “Check for updates”. If a new version is available, quit RStudio, and download the latest version for RStudio.\nTo check which version of R you are using, start RStudio and the first thing that appears in the console indicates the version of R you are running. Alternatively, you can type sessionInfo(), which will also display which version of R you are running. Go on the CRAN website and check whether a more recent version is available. If so, please download and install it. You can check here for more information on how to remove old versions from your system if you wish to do so.\n\n\n\nIf you don’t have R and RStudio installed\n\nDownload R from the CRAN website.\nRun the .exe file that was just downloaded\nGo to the RStudio download page\nUnder Installers select RStudio x.yy.zzz - Windows 10/11 (where x, y, and z represent version numbers)\nDouble click the file to install it\nOnce it’s installed, open RStudio to make sure it works and you don’t get any error messages.\n\n\n\n\nmacOS\n\nIf you already have R and RStudio installed\n\nOpen RStudio, and click on “Help” &gt; “Check for updates”. If a new version is available, quit RStudio, and download the latest version for RStudio.\nTo check the version of R you are using, start RStudio and the first thing that appears on the terminal indicates the version of R you are running. Alternatively, you can type sessionInfo(), which will also display which version of R you are running. Go on the CRAN website and check whether a more recent version is available. If so, please download and install it.\n\n\n\nIf you don’t have R and RStudio installed\n\nDownload R from the CRAN website.\nSelect the .pkg file for the latest R version\nDouble click on the downloaded file to install R\nIt is also a good idea to install XQuartz (needed by some packages)\nGo to the RStudio download page\nUnder Installers select RStudio x.yy.zzz - Mac OS X 10.15+ (64-bit) (where x, y, and z represent version numbers)\nDouble click the file to install RStudio\nOnce it’s installed, open RStudio to make sure it works and you don’t get any error messages.\n\n\n\n\nLinux\n\nFollow the instructions for your distribution from CRAN, they provide information to get the most recent version of R for common distributions. For most distributions, you could use your package manager (e.g., for Debian/Ubuntu run sudo apt-get install r-base, and for Fedora sudo yum install R), but we don’t recommend this approach as the versions provided by this are usually out of date. In any case, make sure you have at least R 3.3.1.\nGo to the RStudio download page\nUnder Installers select the version that matches your distribution, and install it with your preferred method (e.g., with Debian/Ubuntu sudo dpkg -i   rstudio-x.yy.zzz-amd64.deb at the terminal).\nOnce it’s installed, open RStudio to make sure it works and you don’t get any error messages."
  },
  {
    "objectID": "ex1.html",
    "href": "ex1.html",
    "title": "Example 1: Stability of seagrass ecosystems in Florida Bay",
    "section": "",
    "text": "This vignette uses hypervolumes to understand the temporal stability of seagrass ecosystems. Hypervolumes are generated using common seagrass monitoring metrics yearly from 2007-2023 across four basins in Florida Bay, USA. Centroid distance is used to compare mean conditions across all years to determine temporal stability and variable importance is calculated to determine the metric driving stability within each basin.\nR script"
  },
  {
    "objectID": "ex1.html#stability-of-seagrass-ecosystems-in-florida-bay",
    "href": "ex1.html#stability-of-seagrass-ecosystems-in-florida-bay",
    "title": "Example 1: Stability of seagrass ecosystems in Florida Bay",
    "section": "",
    "text": "This vignette uses hypervolumes to understand the temporal stability of seagrass ecosystems. Hypervolumes are generated using common seagrass monitoring metrics yearly from 2007-2023 across four basins in Florida Bay, USA. Centroid distance is used to compare mean conditions across all years to determine temporal stability and variable importance is calculated to determine the metric driving stability within each basin.\nR script"
  },
  {
    "objectID": "ex1.html#data",
    "href": "ex1.html#data",
    "title": "Example 1: Stability of seagrass ecosystems in Florida Bay",
    "section": "data",
    "text": "data\nThe data used for this example comes from the South Florida Fisheries Habitat Assessment Program which monitors seagrass habitats annually using quadrat samples. The benthic cover data consists of data from 4 basins and measures 6 metrics of the SAV community. Data is averaged across stations for each metric.\n\nBASIN = Basin sampled\nYEAR = year of monitoring\nSTATION = monitoring station\nTT = Thalassia testudium percent cover\nHW = Halodule wrightii percent cover\nSF = Syringodium filliforme percent cover\nTMA = total macroalgae percent cover\nTDR = total drift algae percent cover\nsg_rich = seagrass species richness\n\n\n\n\n\nMap of sampling basins\n\n\n\n# load libraries\nlibrary(tidyverse)\nlibrary(hypervolume)\n## Loading required package: Rcpp\n\n# load sav monitoring data \ndf = read_csv('data/FLbay_SAV.csv') \n## Rows: 1919 Columns: 9\n## ── Column specification ────────────────────────────────────────────────────────\n## Delimiter: \",\"\n## chr (1): BASIN\n## dbl (8): YEAR, STATION, TT, HW, SF, TMA, TDR, sg_rich\n## \n## ℹ Use `spec()` to retrieve the full column specification for this data.\n## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\nhead(df)\n## # A tibble: 6 × 9\n##   BASIN  YEAR STATION     TT    HW    SF    TMA    TDR sg_rich\n##   &lt;chr&gt; &lt;dbl&gt;   &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;   &lt;dbl&gt;\n## 1 EAG    2007       1 0.135  0         0 0.0262 0         1   \n## 2 EAG    2007       2 0.0986 0         0 0.0471 0         1   \n## 3 EAG    2007       3 0.15   0         0 0.03   0         1   \n## 4 EAG    2007       4 0.3    0         0 0.07   0         1   \n## 5 EAG    2007       5 0.03   0.005     0 0.03   0         1.17\n## 6 EAG    2007       6 0.206  0         0 0.0262 0.0188    1"
  },
  {
    "objectID": "ex1.html#prepare-data",
    "href": "ex1.html#prepare-data",
    "title": "Example 1: Stability of seagrass ecosystems in Florida Bay",
    "section": "Prepare data",
    "text": "Prepare data\nBecause hypervolumes can be generated with any continuous data as an axes, many of the times the units are not combatible. Blonder et al. 2014 & 2018 to convert all of the axes into the same units. This can be done by taking the z-score of the values to convert units into standard deviations. Z-scoring data can be done with the formula: \\[ z = \\frac{x_{i}-\\overline{x}}{sd} \\] Where \\(x_{i}\\) is a value, \\(\\overline{x}\\) is the mean, and \\(sd\\) is the standard deviation. By z-scoring each axis, 0 is the mean of that axis, a value of 1 means that the value is 1 standard deviation above the global mean of that axis, and a value of -1 is 1 standard deviation below the global mean of the axis. In R this can be done manually or with the scale() function.\nHypervolumes cannot be made when all values for a single axis are the same (e.g. all values 0 for a species cover in a basin for a year), so we can add a tiny bit of variation in order to make the hypervolume.\nWe then can nest() the data to take advantage of the purr package and map().\n\n# z-score and nest data to make hypervolume\nset.seed(14)\ndf = df |&gt; \n  # z score data across all sites and years\n  mutate(across(c(TT:sg_rich), scale), \n  # add tiny amount so when all values the same can make hv       \n         across(c(TT:sg_rich), \n                ~map_dbl(., ~. + rnorm(1, mean = 0, sd = 0.0001)))) |&gt; \n  # remove station from dataset\n  select(-STATION) |&gt; \n  # nest data by basin and year\n  group_by(BASIN, YEAR) |&gt; \n  nest() \nhead(df)\n## # A tibble: 6 × 3\n## # Groups:   BASIN, YEAR [6]\n##   BASIN  YEAR data             \n##   &lt;chr&gt; &lt;dbl&gt; &lt;list&gt;           \n## 1 EAG    2007 &lt;tibble [31 × 6]&gt;\n## 2 EAG    2008 &lt;tibble [31 × 6]&gt;\n## 3 EAG    2009 &lt;tibble [31 × 6]&gt;\n## 4 EAG    2010 &lt;tibble [31 × 6]&gt;\n## 5 EAG    2011 &lt;tibble [31 × 6]&gt;\n## 6 EAG    2012 &lt;tibble [31 × 6]&gt;"
  },
  {
    "objectID": "ex1.html#generate-hypervolumes",
    "href": "ex1.html#generate-hypervolumes",
    "title": "Example 1: Stability of seagrass ecosystems in Florida Bay",
    "section": "Generate hypervolumes",
    "text": "Generate hypervolumes\nHypervolumes are a multidimensional tool that is based on Hutchinson’s n-dimensional niche concept and we can build them with the hypervolume package.\n\nWith a nested dataset of our columns that we want to build hypervolumes for we can use mutate() and map() to generate the hypervolume.\nWe can also use map() and get_centroid() to extract centroid values of each hypervolume.\n\n# generate hypervolumes\ndf = df |&gt; \n  mutate(hv = map(data, \\(data) hypervolume_gaussian(data, name = paste(BASIN,YEAR,sep = '_'),\n                                                     samples.per.point = 1000,\n                                                     kde.bandwidth = estimate_bandwidth(data), \n                                                     sd.count = 3, \n                                                     quantile.requested = 0.95, \n                                                     quantile.requested.type = \"probability\", \n                                                     chunk.size = 1000, \n                                                     verbose = F)),\n         centroid = map(hv, \\(hv) get_centroid(hv)))\n\n** Do not try to open dataframe with hv column it will hang because it is too big\n\nhead(df)\n## # A tibble: 6 × 5\n## # Groups:   BASIN, YEAR [6]\n##   BASIN  YEAR data              hv         centroid \n##   &lt;chr&gt; &lt;dbl&gt; &lt;list&gt;            &lt;list&gt;     &lt;list&gt;   \n## 1 EAG    2007 &lt;tibble [31 × 6]&gt; &lt;Hypervlm&gt; &lt;dbl [6]&gt;\n## 2 EAG    2008 &lt;tibble [31 × 6]&gt; &lt;Hypervlm&gt; &lt;dbl [6]&gt;\n## 3 EAG    2009 &lt;tibble [31 × 6]&gt; &lt;Hypervlm&gt; &lt;dbl [6]&gt;\n## 4 EAG    2010 &lt;tibble [31 × 6]&gt; &lt;Hypervlm&gt; &lt;dbl [6]&gt;\n## 5 EAG    2011 &lt;tibble [31 × 6]&gt; &lt;Hypervlm&gt; &lt;dbl [6]&gt;\n## 6 EAG    2012 &lt;tibble [31 × 6]&gt; &lt;Hypervlm&gt; &lt;dbl [6]&gt;\n\nIf wanting to save you can save output as .rds\n\nsaveRDS(df, 'data/SAV_hvs.rds')"
  },
  {
    "objectID": "ex1.html#plotting-hypervolumes",
    "href": "ex1.html#plotting-hypervolumes",
    "title": "Example 1: Stability of seagrass ecosystems in Florida Bay",
    "section": "plotting hypervolumes",
    "text": "plotting hypervolumes\nWe can plot multiple hypervolumes by joining them together\n\nhvj = hypervolume_join(df$hv[[1]], df$hv[[2]])\n\nplot(hvj, pairplot = T, colors=c('goldenrod','blue'),\n     show.3d=FALSE,plot.3d.axes.id=NULL,\n     show.axes=TRUE, show.frame=TRUE,\n     show.random=T, show.density=TRUE,show.data=F,\n     show.legend=T, limits=c(-5,5), \n     show.contour=F, contour.lwd= 2, \n     contour.type='alphahull', \n     contour.alphahull.alpha=0.25,\n     contour.ball.radius.factor=1, \n     contour.kde.level=0.01,\n     contour.raster.resolution=100,\n     show.centroid=TRUE, cex.centroid=2,\n     point.alpha.min=0.2, point.dark.factor=0.5,\n     cex.random=0.5,cex.data=1,cex.axis=1.5,cex.names=2,cex.legend=2,\n     num.points.max.data = 100000, num.points.max.random = 200000, reshuffle=TRUE,\n     plot.function.additional=NULL,\n     verbose=FALSE\n)"
  },
  {
    "objectID": "ex1.html#centroid-distance",
    "href": "ex1.html#centroid-distance",
    "title": "Example 1: Stability of seagrass ecosystems in Florida Bay",
    "section": "Centroid distance",
    "text": "Centroid distance\nWe can use the centroid distance to compare mean conditions between years to understand the stability. Centroid distance can be calculated by a set of hypervolumes. This can be done by creating a data frame with all of the possible year combinations, and merging dataframes together to easily join. We can subtract the centroids from each comparison to generate the centroid difference of each axis.\n\n# comparison of across each year\ndf_y= tibble(y1 = unique(df$YEAR),\n             y2 = unique(df$YEAR)) |&gt; \n  expand(y1,y2)\n\n# make all unique year comparisons \ndf_y = df_y[!duplicated(t(apply(df_y,1,sort))),] %&gt;% \n  filter(!(y1 == y2))\n\n# make two df to join all unique comparisons  \ndf1 = df |&gt; \n  select(BASIN, y1 = YEAR, hv1 = hv, cent1 = centroid)\n\ndf2 = df |&gt; \n  select(BASIN, y2 = YEAR, hv2 = hv, cent2 = centroid)\n\n\n# create data frame of all data and make yearly comparisons\ndf_cd = tibble(BASIN = rep(unique(df$BASIN),\n                           each = nrow(df_y)),\n               y1 = rep(df_y$y1, times = length(unique(df$BASIN))),\n               y2 = rep(df_y$y2, times = length(unique(df$BASIN)))) |&gt; \n  inner_join(df1, by = c('BASIN', 'y1')) |&gt; \n  inner_join(df2, by = c('BASIN', 'y2')) |&gt; \n  mutate(ychange = y2-y1,\n  # join hypervolumees in a set for centroid distance\n         set = map2(hv1,hv2, \\(hv1, hv2) hypervolume_set(hv1, hv2, check.memory = F, verbose = F)),\n  # calculate centroid distance \n         dist_cent = map2_dbl(hv1, hv2, \\(hv1,hv2) hypervolume_distance(hv1, hv2, type = 'centroid', check.memory=F)),\n  # calculate the difference of centroid of each axis\n         dif = map2(cent1, cent2, \\(cent1,cent2) cent2 - cent1)) |&gt; \n  #unnest centroid differences\n  unnest_wider(dif) |&gt; \n  # select only metrics of interest\n  select(BASIN, y1, y2, ychange,  \n         dist_cent, TT, HW, SF, sg_rich, TMA, TDR)\n\n# save output\nwrite_csv(df_cd, 'data/SAV_centDist.csv')\n\n\n## Rows: 465 Columns: 11\n## ── Column specification ────────────────────────────────────────────────────────\n## Delimiter: \",\"\n## chr  (1): BASIN\n## dbl (10): y1, y2, ychange, dist_cent, TT, HW, SF, sg_rich, TMA, TDR\n## \n## ℹ Use `spec()` to retrieve the full column specification for this data.\n## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\ndf_cd\n## # A tibble: 465 × 11\n##    BASIN    y1    y2 ychange dist_cent     TT      HW        SF  sg_rich     TMA\n##    &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt;   &lt;dbl&gt;     &lt;dbl&gt;  &lt;dbl&gt;   &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;   &lt;dbl&gt;\n##  1 EAG    2007  2008       1     0.502 -0.109 -0.0440  -1.15e-5  0.0104   0.0467\n##  2 EAG    2007  2009       2     0.493 -0.262 -0.0265  -5.03e-5 -0.0846   0.0631\n##  3 EAG    2007  2010       3     0.576 -0.174 -0.0810  -3.60e-5 -0.143    0.303 \n##  4 EAG    2007  2011       4     0.616 -0.210 -0.0625  -2.13e-5 -0.0286   0.572 \n##  5 EAG    2007  2012       5     0.373 -0.150 -0.0462  -3.45e-5  0.0162   0.329 \n##  6 EAG    2007  2013       6     0.227 -0.140 -0.0291   9.11e-6  0.0763   0.0580\n##  7 EAG    2007  2014       7     0.454 -0.409 -0.0134  -2.21e-5 -0.0539   0.0827\n##  8 EAG    2007  2015       8     0.564 -0.445 -0.0243   1.43e-5  0.00913  0.315 \n##  9 EAG    2007  2016       9     0.490 -0.320 -0.0981  -1.55e-5 -0.170    0.169 \n## 10 EAG    2007  2017      10     0.339 -0.210 -0.0607  -2.36e-5 -0.0816  -0.0509\n## # ℹ 455 more rows\n## # ℹ 1 more variable: TDR &lt;dbl&gt;\n\nPlot centroid distance for each basin.\n\ndf_cd = read_csv('data/SAV_centDist.csv') |&gt; \n  mutate(BASIN = factor(BASIN, levels = \n                          c('JON', 'RKB', 'RAN', 'EAG')))\n## Rows: 465 Columns: 11\n## ── Column specification ────────────────────────────────────────────────────────\n## Delimiter: \",\"\n## chr  (1): BASIN\n## dbl (10): y1, y2, ychange, dist_cent, TT, HW, SF, sg_rich, TMA, TDR\n## \n## ℹ Use `spec()` to retrieve the full column specification for this data.\n## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\nggplot(df_cd, aes(BASIN, dist_cent, fill = BASIN))+\n  geom_hline(aes(yintercept = 1), linetype = 'dashed', linewidth = 1)+\n  geom_point(aes(color = BASIN), size = 1, \n             position=position_jitterdodge(dodge.width = 1, jitter.width = 1))+\n  # geom_errorbar(aes(ymin = lc, ymax = uc), linewidth = 2, width = 0)+\n  geom_boxplot(alpha = 0.6, outliers = F)+\n  labs(x = 'Basin', y = 'Centroid distance')+\n  scale_fill_viridis_d(option = 'turbo')+\n  scale_color_viridis_d(option = 'turbo')+\n  theme_bw()+\n  theme(axis.title = element_text(size = 14), \n        axis.text = element_text(size = 14, colour = \"gray0\"), \n        plot.title = element_text(size = 14, hjust=0.5),\n        panel.grid.major = element_blank(),\n        panel.grid.minor = element_blank(),\n        legend.position = 'none',\n        legend.title = element_text(size = 14),\n        strip.text.x = element_text(size = 14),\n        legend.text = element_text(size = 12))"
  },
  {
    "objectID": "ex1.html#trend-in-stability",
    "href": "ex1.html#trend-in-stability",
    "title": "Example 1: Stability of seagrass ecosystems in Florida Bay",
    "section": "Trend in stability",
    "text": "Trend in stability\nWe can look across the number of years to understand the trend in stability. By fitting three possible models we can determine the trend of time of the centroid distance. When intercept model is the best, we can determine that the trend is static and not changing with the number of years between comparison. If linear, the centroid distance can indicate a shift in state overtime, and a quadratic with a maximum at middle values can indicate a disturbance with recovery in state.\n\nlibrary(MuMIn)\ndf_cd = df_cd |&gt; \n  group_by(BASIN) |&gt;\n  nest() |&gt; \n  # fit intercept, linear, and quadratic model\n  mutate(m_int = map(data, \\(df)lm(dist_cent~1, data = df)),\n         m_lin = map(data, \\(df)lm(dist_cent~ychange, data = df)),\n         m_quad = map(data, \\(df)lm(dist_cent~ychange + I(ychange^2), data = df)),\n         AICc_int = map_dbl(m_int, \\(x) AICc(x)),\n         AICc_lin = map_dbl(m_lin, \\(x) AICc(x)),\n         AICc_quad = map_dbl(m_quad, \\(x) AICc(x)),\n         model = case_when(\n           AICc_int - min(c(AICc_int,AICc_lin,AICc_quad)) &lt;= 4 ~ 'Intercept',\n           AICc_lin &lt; AICc_quad ~ 'Linear',\n           AICc_quad &lt; AICc_lin ~ 'Quadratic'))\n\n# unnest data \nd = df_cd |&gt; \n  select(BASIN, data, model) |&gt; \n  unnest(cols = c(data)) |&gt;  \n  mutate(BASIN = factor(BASIN, levels = \n                          c('JON', 'RKB', 'RAN', 'EAG')))\n\nggplot(d, aes(ychange, dist_cent, color = BASIN))+\n  geom_hline(aes(yintercept = 1), linetype = 'dashed')+\n  geom_point(size = 2.5)+\n  geom_smooth(data = d |&gt; filter(model == 'Intercept'),\n              method = 'lm', formula = y~1, \n              linewidth = 1, color = 'black')+\n  geom_smooth(data = d |&gt; filter(model == 'Linear'),\n              method = 'lm', formula = y~x, \n              linewidth = 1, color = 'black')+\n  geom_smooth(data = d |&gt; filter(model == 'Quadratic'),\n              method = 'lm', formula = y~x+I(x^2), \n              linewidth = 1, color = 'black')+\n  facet_wrap(~BASIN,  nrow = 1)+\n  labs(x = 'Years between comparison', y = 'Centroid distance')+\n  scale_color_viridis_d(option = 'turbo')+\n  theme_bw()+\n  theme(axis.title = element_text(size = 14), \n        axis.text.y = element_text(size = 14, colour = \"black\"),\n        axis.text.x = element_text(size = 12, colour = \"black\"), \n        plot.title = element_text(size = 14, hjust=0.5),\n        panel.grid.major = element_blank(),\n        panel.grid.minor = element_blank(),\n        legend.position = 'none',\n        legend.title = element_text(size = 14),\n        strip.text.x = element_text(size = 14),\n        legend.text = element_text(size = 12))"
  },
  {
    "objectID": "ex1.html#variable-importance",
    "href": "ex1.html#variable-importance",
    "title": "Example 1: Stability of seagrass ecosystems in Florida Bay",
    "section": "Variable importance",
    "text": "Variable importance\nBecuase centroid distance is the multivariate difference in mean conditions between hypervolumes, we can determine the influence of each axis on the overall change. This can be done by removing an axis and calculating the euclidean distance without that axis. Using the formula \\[ imp_x = cd/cd_x - 1\\] where \\(imp_x\\) is the importance of axis \\(x\\), \\(cd\\) is centroid distance with all axes, and \\(cd_x\\) is the centroid distance excluding axis \\(x\\).\n\n# pivot data longer \ndf_c = read_csv('data/SAV_centDist.csv') |&gt; \n  mutate(across(TT:TDR, \\(x) x^2)) |&gt; \n  pivot_longer(TT:TDR, names_to = 'axis', values_to = 'dist')\n## Rows: 465 Columns: 11\n## ── Column specification ────────────────────────────────────────────────────────\n## Delimiter: \",\"\n## chr  (1): BASIN\n## dbl (10): y1, y2, ychange, dist_cent, TT, HW, SF, sg_rich, TMA, TDR\n## \n## ℹ Use `spec()` to retrieve the full column specification for this data.\n## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n# create vector of unique axes\nax = unique(df_c$axis)\n\n# for loop to calculate variable importance of each axis\nfor(i in 1:length(ax)){\n  d = df_c |&gt; \n    # remove axis \n    filter(axis != ax[i]) |&gt; \n    group_by(BASIN,y1,y2,ychange,dist_cent) |&gt; \n    #calculate euclidean distance without axis \n    summarise(cd = sqrt(sum(dist))) |&gt; \n    # calculate importance of axis\n    mutate(imp = (dist_cent/cd) - 1,\n           axis = ax[i])\n  \n  # bind data into new data frame to store \n  if(i == 1){\n    df_imp = d\n  }else{\n    df_imp = bind_rows(df_imp, d)\n  }\n}\n## `summarise()` has grouped output by 'BASIN', 'y1', 'y2', 'ychange'. You can\n## override using the `.groups` argument.\n## `summarise()` has grouped output by 'BASIN', 'y1', 'y2', 'ychange'. You can\n## override using the `.groups` argument.\n## `summarise()` has grouped output by 'BASIN', 'y1', 'y2', 'ychange'. You can\n## override using the `.groups` argument.\n## `summarise()` has grouped output by 'BASIN', 'y1', 'y2', 'ychange'. You can\n## override using the `.groups` argument.\n## `summarise()` has grouped output by 'BASIN', 'y1', 'y2', 'ychange'. You can\n## override using the `.groups` argument.\n## `summarise()` has grouped output by 'BASIN', 'y1', 'y2', 'ychange'. You can\n## override using the `.groups` argument.\n\n# calculate relative importance across all years for each basin\ndf_cdi = df_imp |&gt; \n  #filter(ychange == 1) |&gt;\n  group_by(BASIN,axis) |&gt;\n  summarize(imp = mean(imp)) |&gt;\n  group_by(BASIN) |&gt; \n  mutate(s_imp = imp/max(imp))|&gt; \n  mutate(BASIN = factor(BASIN, levels = \n                          c('JON', 'RKB', 'RAN', 'EAG')),\n         axis = factor(axis, levels = c('TDR', 'TMA', 'sg_rich',\n                                        'SF', 'HW', 'TT')))\n## `summarise()` has grouped output by 'BASIN'. You can override using the\n## `.groups` argument.\n# labeler function for plotting\ny_label_formatter = function(x) {\n  ifelse(x %% 1 == 0, formatC(x, format = \"f\", digits = 0), formatC(x, format = \"f\", digits = 2))\n}\n\nggplot(df_cdi, aes(axis, s_imp, fill = BASIN))+\n  geom_col()+\n  labs(x = 'Variable', y = 'Centroid distance variable importance')+\n  coord_flip()+\n  theme_bw()+\n  facet_wrap(~BASIN,  nrow = 2)+\n  scale_y_continuous(\n    breaks = c(0.0, 0.25, 0.5, 0.75, 1.0),\n    limits = c(0, 1),\n    labels = y_label_formatter) +\n  scale_x_discrete(labels = c('Total drift algae', 'Total Macroalgae', 'Seagrass richness',\n                              expression(italic('Syrngodium filliforme')), \n                              expression(italic('Halodule wrightii')),\n                              expression(italic('Thalassia testudium'))))+\n  scale_fill_viridis_d(option = 'turbo')+\n  theme(axis.title = element_text(size = 14), \n        axis.text = element_text(size = 14, colour = \"gray0\"), \n        plot.title = element_text(size = 14, hjust=0.5),\n        panel.grid.major = element_blank(),\n        panel.grid.minor = element_blank(),\n        legend.position = 'none',\n        legend.title = element_text(size = 14),\n        strip.text.x = element_text(size = 14),\n        legend.text = element_text(size = 12))"
  },
  {
    "objectID": "ex1.html#background-info",
    "href": "ex1.html#background-info",
    "title": "Example 1: Stability of seagrass ecosystems in Florida Bay",
    "section": "Background info",
    "text": "Background info\n\nMerge/Join\nIf two data frames contain different columns of data, then they can be merged together with the family of join functions.\n+left_join() = uses left df as template and joins all matching columns from right df +right_join() = uses right df as template and joins all matching columns from left df +inner_join() = only matches columns contained in both dfs +full_join() = combines all rows in both dfs\n\nlibrary(tidyverse)\n## ── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n## ✔ dplyr     1.1.4     ✔ readr     2.1.5\n## ✔ forcats   1.0.0     ✔ stringr   1.5.1\n## ✔ ggplot2   3.5.1     ✔ tibble    3.2.1\n## ✔ lubridate 1.9.3     ✔ tidyr     1.3.1\n## ✔ purrr     1.0.2     \n## ── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n## ✖ dplyr::filter() masks stats::filter()\n## ✖ dplyr::lag()    masks stats::lag()\n## ℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nleft = tibble(name = c('a', 'b', 'c'),\n              n = c(1, 6, 7), \n              bio = c(100, 43, 57))\n\nright = tibble(name = c('a', 'b', 'd', 'e'),\n               cals = c(500, 450, 570, 600))\n\nleft_join(left, right, by = 'name')\n## # A tibble: 3 × 4\n##   name      n   bio  cals\n##   &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n## 1 a         1   100   500\n## 2 b         6    43   450\n## 3 c         7    57    NA\n\nright_join(left, right, by = 'name')\n## # A tibble: 4 × 4\n##   name      n   bio  cals\n##   &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n## 1 a         1   100   500\n## 2 b         6    43   450\n## 3 d        NA    NA   570\n## 4 e        NA    NA   600\n\ninner_join(left, right, by = 'name')\n## # A tibble: 2 × 4\n##   name      n   bio  cals\n##   &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n## 1 a         1   100   500\n## 2 b         6    43   450\n\nfull_join(left, right, by = 'name')\n## # A tibble: 5 × 4\n##   name      n   bio  cals\n##   &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n## 1 a         1   100   500\n## 2 b         6    43   450\n## 3 c         7    57    NA\n## 4 d        NA    NA   570\n## 5 e        NA    NA   600\n\n# multiple matches\nfish = tibble(species = rep(c('Salmon', 'Cod'),times = 3),\n              year = rep(c(1999,2005,2020), each = 2),\n              catch = c(50, 60, 40, 50, 60, 100))\n\ncol = tibble(species = c('Salmon', 'Cod'),\n             coast = c('West', 'East'))\n\nleft_join(fish, col, by = 'species')\n## # A tibble: 6 × 4\n##   species  year catch coast\n##   &lt;chr&gt;   &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt;\n## 1 Salmon   1999    50 West \n## 2 Cod      1999    60 East \n## 3 Salmon   2005    40 West \n## 4 Cod      2005    50 East \n## 5 Salmon   2020    60 West \n## 6 Cod      2020   100 East\n\n\n\nscaling data\nBecause hypervolumes can be generated with any continuous data as an axes, many of the times the units are not combatible. Blonder et al. 2014 & 2018 to convert all of the axes into the same units. This can be done by taking the z-score of the values to convert units into standard deviations. Z-scoring data can be done with the formula: \\[ z = \\frac{x_{i}-\\overline{x}}{sd} \\] Where \\(x_{i}\\) is a value, \\(\\overline{x}\\) is the mean, and \\(sd\\) is the standard deviation. By z-scoring each axis, 0 is the mean of that axis, a value of 1 means that the value is 1 standard deviation above the global mean of that axis, and a value of -1 is 1 standard deviation below the global mean of the axis. In R this can be done manually or with the scale() function.\n\nfish = tibble(species = rep(c('Salmon', 'Cod'),times = 3),\n              year = rep(c(1999,2005,2020), each = 2),\n              catch = c(50, 60, 40, 50, 60, 100))\n\n#\nfish = fish |&gt; \n  mutate(zcatch1 = (catch - mean(catch))/sd(catch), # manual\n         zcatch2 = scale(catch)) # with scale\n\nfish \n## # A tibble: 6 × 5\n##   species  year catch zcatch1 zcatch2[,1]\n##   &lt;chr&gt;   &lt;dbl&gt; &lt;dbl&gt;   &lt;dbl&gt;       &lt;dbl&gt;\n## 1 Salmon   1999    50  -0.477      -0.477\n## 2 Cod      1999    60   0           0    \n## 3 Salmon   2005    40  -0.953      -0.953\n## 4 Cod      2005    50  -0.477      -0.477\n## 5 Salmon   2020    60   0           0    \n## 6 Cod      2020   100   1.91        1.91\n\n# center = mean, scale = sd\nfish$zcatch2\n##            [,1]\n## [1,] -0.4767313\n## [2,]  0.0000000\n## [3,] -0.9534626\n## [4,] -0.4767313\n## [5,]  0.0000000\n## [6,]  1.9069252\n## attr(,\"scaled:center\")\n## [1] 60\n## attr(,\"scaled:scale\")\n## [1] 20.97618\n\n\n\nnesting data\nOne benefit of tibbles is that they can contain list columns. This means that we can make columns of tibbles that are nested within a dataset. Nesting creates a list-column of data frames; unnesting flattens it back out into regular columns. Nesting is a implicitly summarising operation: you get one row for each group defined by the non-nested columns. This is useful in conjunction with other summaries that work with whole datasets, most notably models. This can be done with the nest() and then flattened with unnest()\n\nfish = tibble(species = rep(c('Salmon', 'Cod'),times = 3),\n              year = rep(c(1999,2005,2020), each = 2),\n              catch = c(50, 60, 40, 50, 60, 100))\n\n# using group_by\nfish_nest = fish |&gt; \n  group_by(species) |&gt; \n  nest()\n\nfish_nest\n## # A tibble: 2 × 2\n## # Groups:   species [2]\n##   species data            \n##   &lt;chr&gt;   &lt;list&gt;          \n## 1 Salmon  &lt;tibble [3 × 2]&gt;\n## 2 Cod     &lt;tibble [3 × 2]&gt;\nfish_nest$data\n## [[1]]\n## # A tibble: 3 × 2\n##    year catch\n##   &lt;dbl&gt; &lt;dbl&gt;\n## 1  1999    50\n## 2  2005    40\n## 3  2020    60\n## \n## [[2]]\n## # A tibble: 3 × 2\n##    year catch\n##   &lt;dbl&gt; &lt;dbl&gt;\n## 1  1999    60\n## 2  2005    50\n## 3  2020   100\n\n# using .by in nest\n# column name becomes data unless you change .key\nfish_nest2 = fish |&gt; \n  nest(.by = year, .key = 'df')\n\nfish_nest2\n## # A tibble: 3 × 2\n##    year df              \n##   &lt;dbl&gt; &lt;list&gt;          \n## 1  1999 &lt;tibble [2 × 2]&gt;\n## 2  2005 &lt;tibble [2 × 2]&gt;\n## 3  2020 &lt;tibble [2 × 2]&gt;\nfish_nest2$df\n## [[1]]\n## # A tibble: 2 × 2\n##   species catch\n##   &lt;chr&gt;   &lt;dbl&gt;\n## 1 Salmon     50\n## 2 Cod        60\n## \n## [[2]]\n## # A tibble: 2 × 2\n##   species catch\n##   &lt;chr&gt;   &lt;dbl&gt;\n## 1 Salmon     40\n## 2 Cod        50\n## \n## [[3]]\n## # A tibble: 2 × 2\n##   species catch\n##   &lt;chr&gt;   &lt;dbl&gt;\n## 1 Salmon     60\n## 2 Cod       100\n\n\n\nmap\n\npurr\nThe newest and new standard package with tidyverse is purr with its set of map() functions. Some similarity to plyr (and base) and dplyr functions but with more consistent names and arguments. Notice that map function can have some specification for the type of output. + map() makes a list. + map_lgl() makes a logical vector. + map_int() makes an integer vector. + map_dbl() makes a double vector. + map_chr() makes a character vector.\n\ndf = iris  |&gt; \n  select(-Species)\n#summary statistics\nmap_dbl(df, mean)\n## Sepal.Length  Sepal.Width Petal.Length  Petal.Width \n##     5.843333     3.057333     3.758000     1.199333\n\n# using map with mutate and nest\nd = tibble(species = rep(c('Salmon', 'Cod'),times = 3),\n           year = rep(c(1999,2005,2020), each = 2),\n           catch = c(50, 60, 40, 50, 60, 100)) |&gt; \n  nest(.by = species) |&gt; \n  mutate(correlation = map(data, \\(data) cor.test(data$year, data$catch)))\n\nd\n## # A tibble: 2 × 3\n##   species data             correlation\n##   &lt;chr&gt;   &lt;list&gt;           &lt;list&gt;     \n## 1 Salmon  &lt;tibble [3 × 2]&gt; &lt;htest&gt;    \n## 2 Cod     &lt;tibble [3 × 2]&gt; &lt;htest&gt;\nd$correlation\n## [[1]]\n## \n##  Pearson's product-moment correlation\n## \n## data:  data$year and data$catch\n## t = 0.96225, df = 1, p-value = 0.5122\n## alternative hypothesis: true correlation is not equal to 0\n## sample estimates:\n##       cor \n## 0.6933752 \n## \n## \n## [[2]]\n## \n##  Pearson's product-moment correlation\n## \n## data:  data$year and data$catch\n## t = 1.963, df = 1, p-value = 0.3\n## alternative hypothesis: true correlation is not equal to 0\n## sample estimates:\n##       cor \n## 0.8910421"
  },
  {
    "objectID": "ex2.html",
    "href": "ex2.html",
    "title": "Example 2: Trait diversity of coral communities",
    "section": "",
    "text": "This vignette uses hypervolumes to understand the spatial variation in trait diversity of coral reef communities. Hypervolumes are generated using species trait data and weighted based on random percent cover of species from mean and sd across all sites within a region. This process is repeated 100 times. Hypervolume size is used to quantify the trait diversity of each community.\nR script"
  },
  {
    "objectID": "ex2.html#trait-diversity-of-coral-communities-in-puerto-rico",
    "href": "ex2.html#trait-diversity-of-coral-communities-in-puerto-rico",
    "title": "Example 2: Trait diversity of coral communities",
    "section": "",
    "text": "This vignette uses hypervolumes to understand the spatial variation in trait diversity of coral reef communities. Hypervolumes are generated using species trait data and weighted based on random percent cover of species from mean and sd across all sites within a region. This process is repeated 100 times. Hypervolume size is used to quantify the trait diversity of each community.\nR script"
  },
  {
    "objectID": "ex2.html#data",
    "href": "ex2.html#data",
    "title": "Example 2: Trait diversity of coral communities",
    "section": "data",
    "text": "data\nThe data used for this example comes from the NOAA which monitors coral benthic communities throughout Puerto Rico. The benthic cover data consists of percent cover (pc = mean percent cover, sd = standard deviation percent cover) from coral species collected across 8 regions. Data is averaged across sites within each region. The coral trait data is based on average values of each trait for each species from published literature values.\n\n\n\nMap of sampling basins\n\n\n\n# load libraries\nlibrary(tidyverse)\n## ── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n## ✔ dplyr     1.1.4     ✔ readr     2.1.5\n## ✔ forcats   1.0.0     ✔ stringr   1.5.1\n## ✔ ggplot2   3.5.1     ✔ tibble    3.2.1\n## ✔ lubridate 1.9.3     ✔ tidyr     1.3.1\n## ✔ purrr     1.0.2     \n## ── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n## ✖ dplyr::filter() masks stats::filter()\n## ✖ dplyr::lag()    masks stats::lag()\n## ℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\nlibrary(hypervolume)\n## Loading required package: Rcpp\nlibrary(truncnorm)\n\n# load trait data\ndf_tr = read_csv('data/coral_traits.csv') \n## Rows: 13 Columns: 6\n## ── Column specification ────────────────────────────────────────────────────────\n## Delimiter: \",\"\n## chr (1): species\n## dbl (5): corallite diameter, growth rate, skeletal density, symbiodinium den...\n## \n## ℹ Use `spec()` to retrieve the full column specification for this data.\n## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\ndf_tr\n## # A tibble: 13 × 6\n##    species                 `corallite diameter` `growth rate` `skeletal density`\n##    &lt;chr&gt;                                  &lt;dbl&gt;         &lt;dbl&gt;              &lt;dbl&gt;\n##  1 Acropora cervicornis                    1.2         111.                1.51 \n##  2 Acropora palmata                        0.65         71.0               1.84 \n##  3 Agaricia spp.                           2.54          1.42              2.16 \n##  4 Colpophyllia natans                    22.5           5.56              0.764\n##  5 Diploria labyrinthifor…                 7             3.99              1.48 \n##  6 Montastraea cavernosa                   6.06          4.51              1.70 \n##  7 Orbicella annularis                     2.45          7.31              1.73 \n##  8 Orbicella faveolata                     2.38          8.59              1.18 \n##  9 Orbicella franksi                       3.08          5.22              2.12 \n## 10 Porites astreoides                      1.39          3.64              1.54 \n## 11 Porites furcata                         1.7          29.6               1.05 \n## 12 Pseudodiploria spp.                     5.87          4.36              1.45 \n## 13 Siderastrea spp.                        3.56          5.32              1.64 \n## # ℹ 2 more variables: `symbiodinium density` &lt;dbl&gt;,\n## #   `colony maximum diameter` &lt;dbl&gt;\n\n# load benthic community percent cover data across regions\n# pc = percent cover 0-100\n# pc_sd = standard deviation in percent cover\ndf_ben = read_csv('data/coral_PC.csv')\n## Rows: 52 Columns: 4\n## ── Column specification ────────────────────────────────────────────────────────\n## Delimiter: \",\"\n## chr (2): species, region\n## dbl (2): pc, pc_sd\n## \n## ℹ Use `spec()` to retrieve the full column specification for this data.\n## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\ndf_ben\n## # A tibble: 52 × 4\n##    species              region              pc  pc_sd\n##    &lt;chr&gt;                &lt;chr&gt;            &lt;dbl&gt;  &lt;dbl&gt;\n##  1 Acropora cervicornis North/Northeast 0.0617  0.237\n##  2 Acropora cervicornis South           0.0536  0.268\n##  3 Acropora cervicornis Southwest       0.16    0.505\n##  4 Acropora cervicornis West            0.0647  0.541\n##  5 Acropora palmata     Southwest       3.94   10.1  \n##  6 Acropora palmata     West            5.04   13.9  \n##  7 Colpophyllia natans  Mona/Desecheo   0.653   1.55 \n##  8 Colpophyllia natans  South           0.467   1.39 \n##  9 Colpophyllia natans  Southwest       0.317   1.05 \n## 10 Colpophyllia natans  Vieques/Culebra 0.0757  0.296\n## # ℹ 42 more rows"
  },
  {
    "objectID": "ex2.html#prep-data",
    "href": "ex2.html#prep-data",
    "title": "Example 2: Trait diversity of coral communities",
    "section": "Prep data",
    "text": "Prep data\nTo generate hypervolumes a random percent cover for each species is generated based on the mean and sd of percent cover of that species across all sites in the region. This process is repeated 100 times.\n\nreps = 100\n\nset.seed(14)\ndf = df_ben |&gt; \n  # join trait data to benthic data\n  left_join(df_tr, by = 'species') |&gt; \n  # duplicate the data to create the number of reps needed\n  slice(rep(1:n(), each=reps))|&gt; \n  # randomly generate percent cover\n  mutate(i = rep(1:reps, times=nrow(df_ben)),\n         percentcover = truncnorm::rtruncnorm(1, a = 0.001, b = 100,\n                                              mean = pc, sd = pc_sd)) |&gt; \n  select(region, `corallite diameter`:`percentcover`)\n\ndf \n## # A tibble: 5,200 × 8\n##    region          `corallite diameter` `growth rate` `skeletal density`\n##    &lt;chr&gt;                          &lt;dbl&gt;         &lt;dbl&gt;              &lt;dbl&gt;\n##  1 North/Northeast                  1.2          111.               1.51\n##  2 North/Northeast                  1.2          111.               1.51\n##  3 North/Northeast                  1.2          111.               1.51\n##  4 North/Northeast                  1.2          111.               1.51\n##  5 North/Northeast                  1.2          111.               1.51\n##  6 North/Northeast                  1.2          111.               1.51\n##  7 North/Northeast                  1.2          111.               1.51\n##  8 North/Northeast                  1.2          111.               1.51\n##  9 North/Northeast                  1.2          111.               1.51\n## 10 North/Northeast                  1.2          111.               1.51\n## # ℹ 5,190 more rows\n## # ℹ 4 more variables: `symbiodinium density` &lt;dbl&gt;,\n## #   `colony maximum diameter` &lt;dbl&gt;, i &lt;int&gt;, percentcover &lt;dbl&gt;"
  },
  {
    "objectID": "ex2.html#hypervolumes",
    "href": "ex2.html#hypervolumes",
    "title": "Example 2: Trait diversity of coral communities",
    "section": "Hypervolumes",
    "text": "Hypervolumes\nValues are z-scored across all sites and species for each replication separately. Here we nest two columns one with all of the input data for the hypervolume (data) and one with a vector of the randomly generated percent cover that will be used to weight the hypervolume (weight). Hypervolume size is extracted from each hypervolume using map_dbl() and get_size().\n\n# z-score across all regions for each rep and generate hypervolumes\ndf = df |&gt; \n  # z-score across regions for each rep\n  group_by(i) |&gt; \n  mutate(across(`corallite diameter`:`colony maximum diameter`, scale)) |&gt; \n  # nest data for each region and rep to make hypervolume\n  group_by(region, i) |&gt; \n  # create a column for the percent cover to weight hypervolume as well as input data\n  nest(weight = percentcover, data = `corallite diameter`:`colony maximum diameter`) |&gt; \n  # create community weighted hypervolumes \n  mutate(hv = map2(data,weight, \\(data,weight) hypervolume_gaussian(data, \n                                                                    name = paste(region,i,sep = '_'),\n                                                                    weight = weight$percentcover,\n                                                                    samples.per.point = 1000,\n                                                                    kde.bandwidth = estimate_bandwidth(data), \n                                                                    sd.count = 3, \n                                                                    quantile.requested = 0.95, \n                                                                    quantile.requested.type = \"probability\", \n                                                                    chunk.size = 1000, \n                                                                    verbose = F)),\n  # extrace size for each hypervolume \n          hv_size = map_dbl(hv, \\(hv) get_volume(hv)))\n\n** Do not try to view df in rstudio it will freeze your r since it is too big\n\nhead(df)\n## # A tibble: 6 × 6\n## # Groups:   region, i [6]\n##   region              i weight           data             hv         hv_size\n##   &lt;chr&gt;           &lt;int&gt; &lt;list&gt;           &lt;list&gt;           &lt;list&gt;       &lt;dbl&gt;\n## 1 North/Northeast     1 &lt;tibble [8 × 1]&gt; &lt;tibble [8 × 5]&gt; &lt;Hypervlm&gt;    164.\n## 2 North/Northeast     2 &lt;tibble [8 × 1]&gt; &lt;tibble [8 × 5]&gt; &lt;Hypervlm&gt;    258.\n## 3 North/Northeast     3 &lt;tibble [8 × 1]&gt; &lt;tibble [8 × 5]&gt; &lt;Hypervlm&gt;    307.\n## 4 North/Northeast     4 &lt;tibble [8 × 1]&gt; &lt;tibble [8 × 5]&gt; &lt;Hypervlm&gt;    268.\n## 5 North/Northeast     5 &lt;tibble [8 × 1]&gt; &lt;tibble [8 × 5]&gt; &lt;Hypervlm&gt;    218.\n## 6 North/Northeast     6 &lt;tibble [8 × 1]&gt; &lt;tibble [8 × 5]&gt; &lt;Hypervlm&gt;    218."
  },
  {
    "objectID": "ex2.html#hypervolume-size",
    "href": "ex2.html#hypervolume-size",
    "title": "Example 2: Trait diversity of coral communities",
    "section": "Hypervolume size",
    "text": "Hypervolume size\nWe can calculate the mean and 95% CI of each run to determine the trait diversity of coral communities across each region.\n\n# plot hypervolume size\nd = df |&gt; \n  group_by(region) |&gt; \n  summarize(mean = mean(hv_size),\n            upper = quantile(hv_size, 0.975),\n            lower = quantile(hv_size, 0.025)) |&gt; \n  mutate(region = factor(region, \n                         levels = c('North/Northeast', 'Vieques/Culebra',\n                                    'Southeast', 'South', 'Southwest',\n                                     'West', 'Mona/Desecheo'),\n                         labels = c('North/\\nNortheast', 'Vieques/\\nCulebra',\n                                    'Southeast', 'South', 'Southwest',\n                                    'West', 'Mona/\\nDesecheo')))\n\n\nggplot(d, aes(region, mean, color = region))+\n  geom_pointrange(aes(ymin = lower, ymax = upper), size = 1.5, linewidth = 2)+\n  labs(x = 'Region', y = 'Trait diversity', color = 'Region')+\n  scale_y_log10()+\n  scale_color_viridis_d(option = 'turbo')+\n  theme_bw()+\n  theme(axis.title = element_text(size = 14), \n        axis.text = element_text(size = 14, colour = \"gray0\"), \n        plot.title = element_text(size = 14, hjust=0.5),\n        panel.grid.major = element_blank(),\n        panel.grid.minor = element_blank(),\n        legend.position = 'none',\n        legend.title = element_text(size = 14),\n        strip.text.x = element_text(size = 14),\n        legend.text = element_text(size = 12))"
  },
  {
    "objectID": "ex3.html",
    "href": "ex3.html",
    "title": "Example 3: trophic niche of seagrass consumers",
    "section": "",
    "text": "This vignette uses hypervolumes to quantify the trophic niche of seagrass consumers. Hypervolumes are generated using mean and standard deviation resource use data from stable isotope mixing models. This process is repeated 50 times. Hypervolume overlap metrics, as well as size and centroid distance, are used to understand how consumers niches change between seasons.\nR script"
  },
  {
    "objectID": "ex3.html#seasonal-comparison-of-trophic-niche-of-seagrass-consumers",
    "href": "ex3.html#seasonal-comparison-of-trophic-niche-of-seagrass-consumers",
    "title": "Example 3: trophic niche of seagrass consumers",
    "section": "",
    "text": "This vignette uses hypervolumes to quantify the trophic niche of seagrass consumers. Hypervolumes are generated using mean and standard deviation resource use data from stable isotope mixing models. This process is repeated 50 times. Hypervolume overlap metrics, as well as size and centroid distance, are used to understand how consumers niches change between seasons.\nR script"
  },
  {
    "objectID": "ex3.html#data",
    "href": "ex3.html#data",
    "title": "Example 3: trophic niche of seagrass consumers",
    "section": "data",
    "text": "data\nThe data used for this vignette comes from James et al. 2022. The resource use data consists of mean and standard deviation of four resources for each species in each season based on mixing model outputs. Data comes from species collected across Florida Bay, USA.\n\n\n\nMap of consumer sampling locations\n\n\n\nlibrary(tidyverse)\n## ── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n## ✔ dplyr     1.1.4     ✔ readr     2.1.5\n## ✔ forcats   1.0.0     ✔ stringr   1.5.1\n## ✔ ggplot2   3.5.1     ✔ tibble    3.2.1\n## ✔ lubridate 1.9.3     ✔ tidyr     1.3.1\n## ✔ purrr     1.0.2     \n## ── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n## ✖ dplyr::filter() masks stats::filter()\n## ✖ dplyr::lag()    masks stats::lag()\n## ℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\nlibrary(hypervolume)\n## Loading required package: Rcpp\nlibrary(truncnorm)\n\n# load all data\nd = read_csv('data/CESImixResults.csv')\n## Rows: 56 Columns: 7\n## ── Column specification ────────────────────────────────────────────────────────\n## Delimiter: \",\"\n## chr (3): species, season, source\n## dbl (4): mean, sd, lowend, highend\n## \n## ℹ Use `spec()` to retrieve the full column specification for this data.\n## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\nd\n## # A tibble: 56 × 7\n##    species             season source     mean    sd lowend highend\n##    &lt;chr&gt;               &lt;chr&gt;  &lt;chr&gt;     &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt;   &lt;dbl&gt;\n##  1 Bay anchovy         Wet    Algae     0.02  0.016  0       0.061\n##  2 Mojarra             Wet    Algae     0.004 0.004  0       0.013\n##  3 Pigfish             Wet    Algae     0.008 0.008  0       0.028\n##  4 Pinfish             Wet    Algae     0.028 0.018  0       0.062\n##  5 Pink shrimp         Wet    Algae     0.009 0.008  0       0.031\n##  6 Rainwater killifish Wet    Algae     0.016 0.017  0       0.063\n##  7 Silver perch        Wet    Algae     0.02  0.024  0       0.091\n##  8 Bay anchovy         Wet    Epiphytes 0.3   0.067  0.153   0.418\n##  9 Mojarra             Wet    Epiphytes 0.04  0.02   0.009   0.084\n## 10 Pigfish             Wet    Epiphytes 0.076 0.034  0.019   0.149\n## # ℹ 46 more rows"
  },
  {
    "objectID": "ex3.html#prepare-data",
    "href": "ex3.html#prepare-data",
    "title": "Example 3: trophic niche of seagrass consumers",
    "section": "Prepare data",
    "text": "Prepare data\nHere a custom function HVvalues() is used to generate random points from mean and standard deviation data between end points (lower and upper bounds) using the truncnorm package. Values can then be z-scored.\n*** Note chose either column names or column numbers for ID_rows and names either work but must be the same - df = dataframe or tibble with each row containing - unique entry for making random points - ID_rows = vector of column names or numbers with id information - names = column name or number of name of measure variables - mean = column name or column number of df with mean - sd = column name or column number of df with sd - n = number of points to randomly generate - z_score = T or F, if T z-scores values - end_points = T or F for if random points need to be generated between - a high and low end point (e.g. 5% and 95% interval) - low and high required if end_points = T - low = column name or column number of df with lower bound to sample in - high = column name or column number of df with upper bound to sample in\n\nHVvalues = function(df, ID_rows, names, mean, sd, n, z_score = F,\n                    end_points = F, low = NULL, high = NULL){\n  require(tidyverse)\n  require(truncnorm)\n  \n  # check to see if information is needed to restrict where points are\n  if (end_points){\n    if (is_empty(df[,low]) | is_empty(df[,high])){\n      return(cat('Warning: low and/or high columns not specified \\n\n                  Specific and run again or end_points = F \\n'))\n    }\n  }\n  \n  # check to see if there are more \n  if(T %in% duplicated(df[,c(ID_rows,names)])){\n    return(cat('Warning: some of the rows contain duplicated information \\n\n                make sure data is correct \\n'))\n  }\n  \n  # rename variables to make code work\n  if (is.numeric(mean)){\n    names(df)[mean] = 'Mean'\n  }else {\n    df = df |&gt;  rename(Mean = mean)\n  }\n  \n  if (is.numeric(sd)){\n    names(df)[sd] = 'SD'\n  }else {\n    df = df |&gt;  rename(SD = sd)\n  }\n  \n  if (end_points){\n    if (is.numeric(low)){\n      names(df)[low] = 'lower'\n    }else {\n      df = df |&gt;  rename(lower = low)\n    }\n    \n    if (is.numeric(high)){\n      names(df)[high] = 'upper'\n    }else {\n      df = df |&gt;  rename(upper = high)\n    }\n  }\n  \n  # make sure the names is not numeric \n  if (is.numeric(names)){\n    names = names(df)[names]\n  }\n  \n  labs = unique(as.vector(df[,names])[[1]])\n  # generate random points within bounds\n  if(end_points){\n    \n    df_tot = df |&gt; slice(rep(1:n(), each=n))|&gt; \n      mutate(point = \n               truncnorm::rtruncnorm(1, a = lower, b = upper,\n                                     mean = Mean, sd = SD)) |&gt; \n      ungroup() |&gt; \n      mutate(num = rep(1:n, times=nrow(df))) |&gt;\n      dplyr::select(-Mean, -SD, -lower, -upper)|&gt;\n      pivot_wider(names_from = names, values_from = point)|&gt; \n      dplyr::select(-num)\n  }else {\n    # generate random points outside of bounds\n    df_tot = df |&gt; slice(rep(1:n(), each=n))|&gt;\n      mutate(point = \n               truncnorm::rtruncnorm(1, mean = Mean, sd = SD)) |&gt; \n      ungroup() |&gt; \n      mutate(num = rep(1:n, times=nrow(df))) |&gt;\n      dplyr::select(-Mean, -SD)|&gt;\n      pivot_wider(names_from = names, values_from = point)|&gt; \n      dplyr::select(-num)\n  }\n  if (z_score){\n    df_tot = df_tot  |&gt;  \n      mutate(across(all_of(labs), scale))\n  }\n  \n  return(df_tot)\n  \n}\n\n30 points are generated for each species in each season using map(), and this process is repeated 50 times.\n\n# number or iterations\nreps = 50\n\n# generate points and z-score across iterations\nset.seed(14)\ndf = d |&gt; \n  # duplicate for number of reps\n  slice(rep(1:n(), each=reps))|&gt; \n  mutate(i = rep(1:reps, times=nrow(d))) |&gt; \n  group_by(i) |&gt; \n  nest() |&gt; \n  # apply function to generate random points\n  mutate(points = map(data, \\(data) HVvalues(df = data, ID_rows = c('species', 'season'),\n                                             names = c('source'), \n                                             mean = 'mean', sd = 'sd', n = 30,\n                                             end_points = T, low = 'lowend', high = 'highend',\n                                             z_score = T))) |&gt; \n  select(i, points) |&gt; \n  unnest(points)\n## Warning: There were 3 warnings in `mutate()`.\n## The first warning was:\n## ℹ In argument: `points = map(...)`.\n## ℹ In group 1: `i = 1`.\n## Caused by warning:\n## ! Using an external vector in selections was deprecated in tidyselect 1.1.0.\n## ℹ Please use `all_of()` or `any_of()` instead.\n##   # Was:\n##   data %&gt;% select(low)\n## \n##   # Now:\n##   data %&gt;% select(all_of(low))\n## \n## See &lt;https://tidyselect.r-lib.org/reference/faq-external-vector.html&gt;.\n## ℹ Run `dplyr::last_dplyr_warnings()` to see the 2 remaining warnings.\n\ndf\n## # A tibble: 21,000 × 7\n## # Groups:   i [50]\n##        i species     season Algae[,1] Epiphytes[,1] Mangrove[,1] Seagrass[,1]\n##    &lt;int&gt; &lt;chr&gt;       &lt;chr&gt;      &lt;dbl&gt;         &lt;dbl&gt;        &lt;dbl&gt;        &lt;dbl&gt;\n##  1     1 Bay anchovy Wet    -0.748           0.260          1.99      -0.330 \n##  2     1 Bay anchovy Wet     0.282           0.332          2.15      -0.466 \n##  3     1 Bay anchovy Wet     0.456          -0.0134         2.10       0.0613\n##  4     1 Bay anchovy Wet     0.186          -0.648          2.39      -0.260 \n##  5     1 Bay anchovy Wet    -0.478          -0.265          1.82      -0.232 \n##  6     1 Bay anchovy Wet     0.0711         -0.369          1.76       0.0775\n##  7     1 Bay anchovy Wet    -0.490          -0.675          1.66      -0.481 \n##  8     1 Bay anchovy Wet     0.000560       -0.465          2.24      -0.322 \n##  9     1 Bay anchovy Wet    -0.625          -0.158          2.34      -0.619 \n## 10     1 Bay anchovy Wet    -0.0106         -0.425          2.07      -0.670 \n## # ℹ 20,990 more rows"
  },
  {
    "objectID": "ex3.html#hypervolumes",
    "href": "ex3.html#hypervolumes",
    "title": "Example 3: trophic niche of seagrass consumers",
    "section": "Hypervolumes",
    "text": "Hypervolumes\nHypervolumes are generated for each species and season and the size of each hypervolume is calculated.\n\ndf = df |&gt; \n  group_by(species, season, i) |&gt; \n  nest() |&gt; \n  mutate(hv = map(data, \\(data) hypervolume_gaussian(data, name = paste(species, season, i,sep = '_'),\n                                                     samples.per.point = 500,\n                                                     kde.bandwidth = estimate_bandwidth(data), \n                                                     sd.count = 3, \n                                                     quantile.requested = 0.95, \n                                                     quantile.requested.type = \"probability\", \n                                                     chunk.size = 1000, \n                                                     verbose = F)),\n         hv_size = map_dbl(hv, \\(hv) get_volume(hv)))\n\n** Do not try to view df in rstudio it will freeze your r since it is too big\n\nhead(df)\n## # A tibble: 6 × 7\n## # Groups:   species, season, i [6]\n##       i species             season data              hv         hv_size centroid\n##   &lt;int&gt; &lt;chr&gt;               &lt;chr&gt;  &lt;list&gt;            &lt;list&gt;       &lt;dbl&gt; &lt;list&gt;  \n## 1     1 Bay anchovy         Wet    &lt;tibble [30 × 4]&gt; &lt;Hypervlm&gt;  3.27   &lt;dbl&gt;   \n## 2     1 Mojarra             Wet    &lt;tibble [30 × 4]&gt; &lt;Hypervlm&gt;  0.0909 &lt;dbl&gt;   \n## 3     1 Pigfish             Wet    &lt;tibble [30 × 4]&gt; &lt;Hypervlm&gt;  1.22   &lt;dbl&gt;   \n## 4     1 Pinfish             Wet    &lt;tibble [30 × 4]&gt; &lt;Hypervlm&gt;  3.09   &lt;dbl&gt;   \n## 5     1 Pink shrimp         Wet    &lt;tibble [30 × 4]&gt; &lt;Hypervlm&gt;  0.962  &lt;dbl&gt;   \n## 6     1 Rainwater killifish Wet    &lt;tibble [30 × 4]&gt; &lt;Hypervlm&gt;  6.32   &lt;dbl&gt;"
  },
  {
    "objectID": "ex3.html#hypervolume-metrics",
    "href": "ex3.html#hypervolume-metrics",
    "title": "Example 3: trophic niche of seagrass consumers",
    "section": "Hypervolume metrics",
    "text": "Hypervolume metrics\nCombine each species and season to calculate the overlap and centroid distance of each species\n\nov_sn = df |&gt; \n  select(species, season, hv, hv_size) |&gt; \n  pivot_wider(names_from = season, values_from = c(hv,hv_size)) |&gt; \n  mutate(size_rat = hv_size_Dry/hv_size_Wet,\n         set = map2(hv_Wet,hv_Dry, \\(hv1, hv2) hypervolume_set(hv1, hv2, check.memory = F, verbose = F)),\n         ov = map(set, \\(set) hypervolume_overlap_statistics(set)),\n         dist_cent = map2_dbl(hv_Wet,hv_Dry, \\(hv1,hv2) hypervolume_distance(hv1, hv2, type = 'centroid', check.memory=F))) |&gt; \n  unnest_wider(ov) |&gt; \n  select(species, i, hv_size_Wet, hv_size_Dry, \n         size_rat, jaccard, sorensen,\n         uniq_Wet = frac_unique_1, uniq_Dry = frac_unique_2, \n         dist_cent)\n\n\n## Rows: 350 Columns: 10\n## ── Column specification ────────────────────────────────────────────────────────\n## Delimiter: \",\"\n## chr (1): species\n## dbl (9): i, hv_size_Wet, hv_size_Dry, size_rat, jaccard, sorensen, uniq_Wet,...\n## \n## ℹ Use `spec()` to retrieve the full column specification for this data.\n## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\nHypervolume size\n\ndf = ov_sn |&gt; \n  pivot_longer(hv_size_Wet:hv_size_Dry,names_to = 'season',\n               values_to = 'vol') |&gt; \n  group_by(species, season) |&gt; \n  summarize(mean = mean(vol),\n            median = median(vol),\n            low = quantile(vol, 0.025),\n            up = quantile(vol, 0.975)) |&gt; \n  mutate(season = factor(season, levels = c('hv_size_Wet', \n                                            'hv_size_Dry')))\n## `summarise()` has grouped output by 'species'. You can override using the\n## `.groups` argument.\n\nggplot(df, aes(x = species, y = mean, color = season))+\n  geom_pointrange(aes(ymin = low, ymax = up),\n                  size = 1.5, linewidth = 1.5, fatten = 2, \n                  position=position_dodge(width = 0.5))+\n  labs(x = 'Species', y = 'Trophic niche width',\n       color = 'Season') +\n  scale_fill_manual(values = c('hv_size_Wet' = 'skyblue3', \n                               'hv_size_Dry' = 'indianred3'),\n                    labels = c('hv_size_Wet' = 'Wet', \n                               'hv_size_Dry' = 'Dry')) +\n  scale_color_manual(values = c('hv_size_Wet' = 'skyblue3', \n                                'hv_size_Dry' = 'indianred3'),\n                     labels = c('hv_size_Wet' = 'Wet',\n                                'hv_size_Dry' = 'Dry')) +\n  scale_x_discrete(labels = c(\"Bay \\nanchovy\",\n                              \"Mojarra\",\n                              \"Pigfish\",\n                              \"Pinfish\",\n                              \"Pink \\nshrimp\",\n                              \"Rainwater \\nkillifish\",\n                              \"Silver \\nperch\" ))+\n  theme_bw()+\n  theme(axis.title = element_text(size = 14), \n        axis.text.y = element_text(size = 14, colour = \"black\"), \n        axis.text.x = element_text(size = 12, colour = \"black\"),\n        plot.title = element_text(size = 14, hjust=0.5),\n        panel.grid.major = element_blank(),\n        panel.grid.minor = element_blank(),\n        legend.position = 'right',\n        legend.title = element_text(size = 14),\n        strip.text.x = element_text(size = 14),\n        legend.text = element_text(size = 12))\n## Warning: No shared levels found between `names(values)` of the manual scale and the\n## data's fill values.\n\n\n\n\n\n\nCentroid distance\n\ncols = c(\"Pinfish\" = 'yellow2',\n         \"Mojarra\" = 'slategray4',\n         \"Silver perch\" = 'snow3',\n         \"Bay anchovy\" = 'deepskyblue1',\n         \"Pigfish\" = 'orange', \n         \"Pink shrimp\" = 'pink',\n         \"Rainwater killifish\" = 'firebrick',\n         'All' = 'black')\ndf = ov_sn|&gt; \n  group_by(species) |&gt; \n  summarize(mean = mean(dist_cent),\n            median = median(dist_cent),\n            low = quantile(dist_cent, 0.025),\n            up = quantile(dist_cent, 0.975))\n\nggplot(df, aes(x = species, y = mean, color = species))+\n  geom_hline(aes(yintercept = 1), linewidth = 1, linetype = 'dashed')+\n  geom_pointrange(aes(ymin = low, ymax = up),\n                  size = 1.5, linewidth = 1.5, fatten = 2, \n                  position=position_dodge(width = 0.5))+\n  labs(x = NULL, y = 'Centroid distance') +\n  scale_x_discrete(labels = c(\"Bay \\nanchovy\",\n                              \"Mojarra\",\n                              \"Pigfish\",\n                              \"Pinfish\",\n                              \"Pink \\nshrimp\",\n                              \"Rainwater \\nkillifish\",\n                              \"Silver \\nperch\" ))+\n  scale_color_manual(values = cols)+\n  scale_y_continuous(limits = c(0,4.1))+\n  theme_bw()+\n  theme(axis.title = element_text(size = 14), \n        axis.text.y = element_text(size = 14, colour = \"black\"), \n        axis.text.x = element_text(size = 12, colour = \"black\"),\n        plot.title = element_text(size = 14, hjust=0.5),\n        panel.grid.major = element_blank(),\n        panel.grid.minor = element_blank(),\n        legend.position = 'none',\n        legend.title = element_text(size = 14),\n        strip.text.x = element_text(size = 14),\n        legend.text = element_text(size = 12))\n\n\n\n\n\n\nOverlap\n\ndf = ov_sn|&gt; \n  group_by(species) |&gt; \n  summarize(mean = mean(sorensen),\n            median = median(sorensen),\n            low = quantile(sorensen, 0.025),\n            up = quantile(sorensen, 0.975))\n\nggplot(df, aes(x = species, y = mean, color = species))+\n  geom_pointrange(aes(ymin = low, ymax = up),\n                  size = 1.5, linewidth = 1.5, fatten = 2, \n                  position=position_dodge(width = 0.5))+\n  labs(x = NULL, y = 'Niche overlap') +\n  scale_x_discrete(labels = c(\"All\",\n                              \"Bay \\nanchovy\",\n                              \"Mojarra\",\n                              \"Pigfish\",\n                              \"Pinfish\",\n                              \"Pink \\nshrimp\",\n                              \"Rainwater \\nkillifish\",\n                              \"Silver \\nperch\" ))+\n  scale_color_manual(values = cols)+\n  theme_bw()+\n  theme(axis.title = element_text(size = 14), \n        axis.text.y = element_text(size = 14, colour = \"black\"), \n        axis.text.x = element_text(size = 12, colour = \"black\"),\n        plot.title = element_text(size = 14, hjust=0.5),\n        panel.grid.major = element_blank(),\n        panel.grid.minor = element_blank(),\n        legend.position = 'none',\n        legend.title = element_text(size = 14),\n        strip.text.x = element_text(size = 14),\n        legend.text = element_text(size = 12))\n\n\n\n\n\n\nPercent unique\n\ndf = ov_sn|&gt;  \n  pivot_longer(uniq_Wet:uniq_Dry,names_to = 'season',\n               values_to = 'vol') |&gt; \n  group_by(species, season) |&gt; \n  summarize(mean = mean(vol),\n            median = median(vol),\n            low = quantile(vol, 0.025),\n            up = quantile(vol, 0.975)) |&gt; \n  mutate(season = factor(season, levels = c('uniq_Wet', \n                                            'uniq_Dry')))\n## `summarise()` has grouped output by 'species'. You can override using the\n## `.groups` argument.\n\nggplot(df, aes(x = species, y = mean, color = season))+\n  geom_pointrange(aes(ymin = low, ymax = up),\n                  size = 1.5, linewidth = 1.5, fatten = 2, \n                  position=position_dodge(width = 0.5))+\n  labs(x = 'Species', y = 'Niche volume unique',\n       color = 'Season') +\n  scale_fill_manual(values = c('uniq_Wet' = 'skyblue3', \n                               'uniq_Dry' = 'indianred3'),\n                    labels = c('uniq_Wet' = 'Wet', \n                               'uniq_Dry' = 'Dry')) +\n  scale_color_manual(values = c('uniq_Wet' = 'skyblue3', \n                                'uniq_Dry' = 'indianred3'),\n                     labels = c('uniq_Wet' = 'Wet',\n                                'uniq_Dry' = 'Dry')) +\n  scale_x_discrete(labels = c(\"Bay \\nanchovy\",\n                              \"Mojarra\",\n                              \"Pigfish\",\n                              \"Pinfish\",\n                              \"Pink \\nshrimp\",\n                              \"Rainwater \\nkillifish\",\n                              \"Silver \\nperch\" ))+\n  theme_bw()+\n  theme(axis.title = element_text(size = 14), \n        axis.text.y = element_text(size = 14, colour = \"black\"), \n        axis.text.x = element_text(size = 12, colour = \"black\"),\n        plot.title = element_text(size = 14, hjust=0.5),\n        panel.grid.major = element_blank(),\n        panel.grid.minor = element_blank(),\n        legend.position = 'right',\n        legend.title = element_text(size = 14),\n        strip.text.x = element_text(size = 14),\n        legend.text = element_text(size = 12))\n## Warning: No shared levels found between `names(values)` of the manual scale and the\n## data's fill values."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "ISBW 15 Workshop: Hypervolume modeling",
    "section": "",
    "text": "BSC 6926 B52: R workshop on population and community ecological modeling\nThis is the course website for the R workshop that coincides with PCB 5423 (Advanced Ecology). This website will have the Rmarkdown lessons for each workshop. Find the course schedule and Syllabus here. This course will be based in R and information about downloading R and Rstudio can be found here.\n\n\nClass Resources\n\nZoom link\nGithub repository for workshop R scripts\nWebsite Github repository\nTextbook for R exercises (S) Stevens, M.H.H. 2010. A primer of ecology with R. ISBN 978-0-387-89881-0 (Electronically available at FIU Library) E-book version\n\n\n\nR Resources\n\nR for Data Science by Hadley Wickham and Garret Grolemund – An introduction to programming with R: https://r4ds.hadley.nz/\n\nQuick-R by datacamp: Quick overview on R programming and statistical approaches. There are more tutorials, but you will be required to register\n\nRStudio Cloud Training Exercises: https://rstudio.cloud/learn/primers\n\nVirtual Ecology Portal/EcoVirtual R Package: Website that provides various examples of population and community models that will be discussed in class and the workshop. There is also an R package (EcoVirtual) you can use to run various models included on this website: http://ecovirtual.ib.usp.br/doku.php?id=start\n\nModernDive: Introductory book on R and statistical inference: https://moderndive.com/index.html\nRstudio: learn R https://education.rstudio.com/learn/beginner/"
  }
]